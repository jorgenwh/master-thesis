\subsection{Advantages and Drawbacks of Methods} \label{discussion:advantages_and_drawbacks_of_methods}
In section \ref{methods} we explored three different methods for GPU accelerating existing Python code.
Each of the methods we explored has a unique set of advantages and drawbacks.
The discipline of designing and implementing GPU programs is quite distinct from the more mainstream discipline of implementing programs meant to run serially on the CPU.
Becoming an expert GPU programmer can in many instances take years with all the technologies and tools available today.
Thus, an interesting dimension when assessing the advantages and drawbacks of the GPU acceleration methods we have explored is how seamless it is to implement the solution, particularly for someone with little or no experience in GPU programming.
%Other metrics we will discuss include how seamless the integration of a solution into Python is, how quickly a solution can be implemented compared to the alternative methods, among other per-method details.
We will additionally consider how seamless integration into Python is, and of course, the potential for performance.

\subsubsection{Using CuPy as a NumPy Drop-in Replacement} \label{discussion:using_cupy_as_a_numpy_drop_in_replacement}
The first GPU acceleration method we explored in section \ref{methods:preliminary_testing}, was to use CuPy, a GPU accelerated array library with an interface designed to closely follow NumPy, as a drop-in replacement for NumPy. 

\paragraph{Advantages}
This method is ideal in cases where an already existing Python solution based on NumPy exists.
Depending on the complexity of the program architecture, replacing the NumPy module with CuPy can yield seamless and immediate GPU acceleration without the need to implement any GPU functionality, understand the GPU hardware or leave the Python ecosystem.
This technique is in such instances, by a large margin, the fastest way of implementing GPU acceleration.
In cases where no existing solution exists to transform, CuPy is still an adequate tool for "quick and dirty" testing with seamless GPU acceleration directly in Python.
Additionally, this method does not require deep knowledge or understanding of the GPU hardware and architecture, as the routines and functions are implemented by the CuPy developers.
That being said, some knowledge about GPUs may still be helpful, as it can guide decision making about what type of NumPy code may best be suited for GPU acceleration and how the data flow may be best optimized.

\paragraph{Drawbacks}
While an advantage of CuPy is that it allows for seamless "quick and dirty" testing directly in Python, this conversely also introduces a drawback of this method.
Many solutions implemented using NumPy are designed for fast processing on the CPU.
While such solutions may seem like good candidates for GPU acceleration, this match is not guaranteed.
Additionally, because NumPy and CuPy are Python libraries, they suffer from many unnecessary data allocations and copies when nested Python expressions with arrays are computed.
An example highlighting this issue is the log of the probability mass function (LOGPMF) described in section \ref{methods:gpu_accelerating_genotyping}.
As the nested LOGPMF expression is computed using CuPy arrays, Python's evaluation rules dictate that the expression must be evaluated one operation at a time.
Thus, a simple expression may allocate and produce many temporary arrays, although only a single output array remains when the expression is fully computed.
These allocations and copies result in a significant spike in global memory requests and memory usage on the GPU, and can be circumvented when implementing custom kernels using either CuPy's JIT compiled kernel support or CUDA in C++.

\subsubsection{Custom C++ Implementations Using CUDA}
The second GPU acceleration method we explored in section \ref{methods:gpu_accelerating_kmer_counting}, was to implement our own solution directly in C++ using the CUDA framework.
We then used pybind11 to create Python bindings for our C++ functionality to gain access directly inside Python.

\paragraph{Advantages}
The clearest advantage of this method is the granular control over the hardware achieved when implementing the solution directly in Nvidia's programming platform: CUDA.
This provides the possibility of closely tailoring the implementation to the problem and using all of CUDA's technologies to optimize and gain the best performance possible.
Additionally, since such an implementation would be created using C++, this allows access to C++ features that are otherwise out of reach in Python, such as thread parallelization.

\paragraph{Drawbacks}
For this method too, its main advantage also yields its greatest drawback.
The CUDA programming platform is vast and provides support that can be extremely useful to solve certain problems effectively, but that also requires deep knowledge and understanding of the GPU hardware- and programming model.
Additionally, since CUDA features are used in C++, the programmer would need to be, at the very least, comfortable with writing software in C++.
Integration to Python also becomes significantly more difficult, as solution are implemented in C++.
Python bindings, using tools such as ctypes or pybind11, are necessary to integrate solutions into the Python ecosystem.
This, in addition to the fact that C++ is a significantly more verbose language than Python, results in production time being vastly greater for solutions implemented using this method, even for an experienced CUDA programmer.

\subsubsection{Custom JIT-Compiled Kernels in Python}
The third and final GPU acceleration method we explored in section \ref{methods:gpu_accelerating_kmer_counting_jit}, was to implement our solution using CuPy's support for JIT (just-in-time) compiled custom kernels.
CuPy, directly in Python through its module interface, provides access to certain CUDA functionality as well as support for creating kernels directly in Python code that are then compiled when the program first encounters them.

\paragraph{Advantages}
This method has many of the same advantages as the method discussed in \ref{discussion:using_cupy_as_a_numpy_drop_in_replacement}, and can be viewed as an extension of the CuPy drop-in for NumPy method.
What it brings in addition to being a drop-in replacement for NumPy is its JIT compiled custom kernel support and, although limited, CUDA functionality support.
This allows for simple array-programming similar to NumPy where it is suitable, and more detailed usage with custom kernels and some other CUDA functionality in cases where the straight-forward array-interface does not suffice.
In section \ref{methods:gpu_accelerating_kmer_counting_jit}, we showed that we could fully re-implement our CUDA hash table directly in Python using CuPy's custom kernel support.
This was all achieved while never leaving Python, meaning a programmer does not need to know C++ in order to implement custom kernels this way.
More additional functionality not used in our implementation of GKAGE is also supported through CuPy, such as CUDA streams cooperative groups and more \cite{cupy}.

\paragraph{Drawbacks}
While it is helpful to be able to implement custom kernels directly in Python code, it is uncertain how much simplicity this in effect introduces.
The kernels implemented using CuPy's custom kernel support still need to adhere to the same programming model as CUDA kernels implemented in C++.
A programmer with little or no knowledge of how the GPU hardware and programming model works will not with ease be able to implement effective kernels this way.
Therefore, we would argue that this advantage does not do much more than alleviate the need to delve into C++ and set up proper compiling and Python bindings.
