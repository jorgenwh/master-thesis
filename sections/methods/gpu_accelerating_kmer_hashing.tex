\subsection{GPU Accelerating \textit{k}mer Hashing} \label{methods:gpu_accelerating_kmer_hashing}
The \textit{k}mer hashing component of KAGE is responsible for reading genomic reads from FASTA, FASTQ or other file types, encoding the reads as 2-bit encoded data and finally hashing all valid \textit{k}mers from the 2-bit encoded reads.
In KAGE, the final product yielded by this component is a 64-bit unsigned integer array where each element is a 2-bit encoded 31-mer represented in the right-most 62 bits of the integer.
Since the number of valid \textit{k}mers in a typical FASTA or FASTQ from sequencing a human genome is extremely vast, the file is usually read, encoded and hashed in chunks to alleviate the required amount of memory.
Functionality for this exists in the BioNumPy Python package.
BioNumPy implements this using NumPy and some parts of npstructures, resulting in an efficient solution that relies on NumPy's fast array operations for its performance.

\subsubsection{Implementation}
The Python package BioNumPy, which provides an implementation for \textit{k}mer encoding and hashing directly in Python, is built on top of NumPy and npstructures.
We utilized the method we described in section \ref{methods:initial_testing} and used CuPy as a drop-in replacement for NumPy to add further GPU acceleration support to npstructures, and to add partial GPU support to BioNumPy.
The resulting pipeline remained the same, but with two notable differences.
\begin{compactenum}
  \item The raw byte chunk read from the FASTA files would be copied directly to the GPU.
  \item The chunk of data received on the GPU would go through the same pipeline of array operations to 2-bit encode and hash the \textit{k}mers, but on the GPU as opposed to the CPU.
\end{compactenum}

\definecolor{cpucolor}{RGB}{255,255,225}
\definecolor{gpucolor}{RGB}{225,255,255}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
  \node at(4.25,3.75)[]{\smaller{CPU}};
  \node at(4.25,2.75)[]{\smaller{GPU}};
  \node at(3.3,3.75)[draw,minimum width=.75cm,minimum height=.75cm,fill=cpucolor]{};
  \node at(3.3,2.75)[draw,minimum width=.75cm,minimum height=.75cm,fill=gpucolor]{};
  \node at(0,1.5)[]{\smaller{\textbf{NumPy pipeline}}};
  % read fasta
  \node at(0,0)[draw,minimum width=2cm,minimum height=1.2cm,fill=cpucolor](start){};
  \node at(0,.25)[]{\smaller{read}};
  \node at(0,-.25)[]{\smaller{FASTA}};
  \draw [thick,-stealth](1.25,0) -- (2,0);
  % cpu2gpu copy
  \node at(3.3,0)[draw,minimum width=2cm,minimum height=1.2cm,fill=cpucolor]{};
  \node at(3.3,.25)[]{\smaller{2-bit}};
  \node at(3.3,-.25)[]{\smaller{encoding}};
  \draw [thick,-stealth](4.65,0) -- (5.4,0);
  % 2-bit encoding
  \node at(6.65,0)[draw,minimum width=2cm,minimum height=1.2cm,fill=cpucolor]{};
  \node at(6.65,.25)[]{\smaller{\textit{k}mer}};
  \node at(6.65,-.25)[]{\smaller{hashing}};
  \draw [thick,-stealth](8,0) -- (8.85,0);
  % arrows
  \draw [thick](6.65,-.95) -- (6.65,-1.75);
  \draw [thick](6.65,-1.75) -- (0,-1.75);
  \draw [thick,-stealth](0,-1.75) -- (0,-.95);
  \node at(3.3,-2.25)[]{\smaller{repeat}};
\end{tikzpicture}
\end{center}
\end{figure}

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
  \node at(1.75,1.5)[]{\smaller{\textbf{CuPy pipeline}}};
  % read fasta
  \node at(0,0)[draw,minimum width=2cm,minimum height=1.2cm,fill=cpucolor](start){};
  \node at(0,.25)[]{\smaller{read}};
  \node at(0,-.25)[]{\smaller{FASTA}};
  \draw [thick,-stealth](1.25,0) -- (2,0);
  % cpu2gpu copy
  \node at(3.3,0)[draw,minimum width=2cm,minimum height=1.2cm,fill=cpucolor]{};
  \node at(3.3,.25)[]{\smaller{cpu2gpu}};
  \node at(3.3,-.25)[]{\smaller{copy}};
  \draw [thick,-stealth](4.65,0) -- (5.4,0);
  % 2-bit encoding
  \node at(6.65,0)[draw,minimum width=2cm,minimum height=1.2cm,fill=gpucolor]{};
  \node at(6.65,.25)[]{\smaller{2-bit}};
  \node at(6.65,-.25)[]{\smaller{encoding}};
  \draw [thick,-stealth](8,0) -- (8.85,0);
  % kmer hashing
  \node at(10.15,0)[draw,minimum width=2cm,minimum height=1.2cm,fill=gpucolor]{};
  \node at(10.15,.25)[]{\smaller{\textit{k}mer}};
  \node at(10.15,-.25)[]{\smaller{hashing}};
  \draw [thick,-stealth](11.50,0) -- (12.35,0);
  % arrows
  \draw [thick](10.15,-.95) -- (10.15,-1.75);
  \draw [thick](10.15,-1.75) -- (0,-1.75);
  \draw [thick,-stealth](0,-1.75) -- (0,-.95);
  \node at(5.05,-2.25)[]{\smaller{repeat}};
\end{tikzpicture}
\caption{
  By using CuPy as a drop-in replacement to add GPU acceleration to KAGE's \textit{k}mer hashing step, we effectively introduced a new step in the pipeline: copying the raw text data read from the FASTA file directly to the GPU to allow for all of BioNumPy's array operations that constitute 2-bit encoding and hashing the \textit{k}mers to be performed on the GPU.
}
\label{methods:gpu_accelerating_kmer_hashing:figures:gpu_pipeline}
\end{center}
\end{figure}

Upon completing the 2-bit encoding and \textit{k}mer hashing of the chunk, the resulting \textit{k}mer array already resides in GPU memory for the counting step.
Previously, when the 2-bit encoding and \textit{k}mer hashing was performed using only the CPU, the resulting \textit{k}mer array would need to be copied to the GPU for counting when deploying the GPU accelerated \textit{k}mer counting functionality detailed in section \ref{methods:gpu_accelerating_kmer_counting}.

\subsubsection{Assessment}
In order to assess the effects of GPU accelerating \textit{k}mer hashing, we measured the total runtime of reading, 2-bit encoding and hashing every valid \textit{k}mer from a FASTA file containing 20 million reads, each of length 150.
The FASTA was read in chunks of 10 million bytes.
We benchmarked this runtime using BioNumPy with the standard NumPy backend, and again using CuPy as the backend to compare.
The benchmarking yielded the following results:
\begin{table}[H]
\begin{center}
\begin{tabular}{lllll}
\multicolumn{1}{l|}{\textbf{Backend}} & \multicolumn{1}{l}{\textbf{Hashing time (seconds)}} &  \\ \cline{1-2}
\multicolumn{1}{l|}{NumPy} & \multicolumn{1}{l}{62.46} &  \\
\multicolumn{1}{l|}{CuPy} & \multicolumn{1}{l}{5.1} &  \\
\end{tabular}
\end{center}
\caption{
  The runtimes found by hashing all valid \textit{k}mers from a set of 20 million DNA reads, each of length 150.
  The FASTA file containing the reads was read in chunks of 10 million bytes, and the BioNumPy library in Python was used to read, 2-bit encode and hash each chunk.
  We ran the benchmark both using NumPy as the backend-library for BioNumPy, meaning the hashing was performed entirely on the CPU using a single thread, and using CuPy as the backend-library for BioNumPy, meaning the raw data read from the FASTA file was copied to the GPU and then 2-bit encoded and hashed there.
}
\label{methods:gpu_accelerating_kmer_hashing:tables:benchmark}
\end{table}

\begin{figure}[H]
\hspace*{7em}
\begin{tikzpicture}[font=\small]
  \pgfplotsset{
    compat=newest,
    xlabel near ticks,
    ylabel near ticks
  }
  \pgfplotsset{compat=1.11,
      /pgfplots/ybar legend/.style={
      /pgfplots/legend image code/.code={%
         \draw[##1,/tikz/.cd,yshift=-0.25em]
          (0cm,0cm) rectangle (3pt,0.8em);},
     },
  }
  \node at(3.5,7.5)(){\textbf{Effect of GPU Accelerating}};
  \node at(3,7)(){\textbf{\textit{k}mer Hashing}};
 
\begin{axis} [
  ylabel={runtime (seconds)},
  xlabel={backend},
  ybar,
  bar width=20pt,
  ymin=0,
  xtick=data,
  axis x line=bottom,
  axis y line=left,
  enlarge x limits=1.25,
  symbolic x coords={NumPy, CuPy},
  xticklabel style={anchor=base, yshift=-\baselineskip},
  /pgf/number format/.cd,fixed,precision=3,
  nodes near coords={\small\pgfmathprintnumber{\pgfplotspointmeta}},
  legend style={anchor=west},
]

\addplot[fill=blue] coordinates {
    (NumPy, 62.46)
    (CuPy, 5.1)
};
\end{axis}
\end{tikzpicture}
%\end{center}
\caption{
  Elapsed time spent reading, 2-bit encoding and hashing all valid \textit{k}mers from 20 million reads in 10 million byte chunks using both NumPy as CuPy to perform the processing on the CPU and GPU respectively.
}
\label{methods:gpu_accelerating_kmer_hashing:figures:benchmark}
\end{figure}

As can be seen in table \ref{methods:gpu_accelerating_kmer_hashing:tables:benchmark}, GPU accelerating BioNumPy's \textit{k}mer hashing functionality, simply by using CuPy as a drop-in replacement for NumPy, yielded a more than 12X speedup when hashing every valid \textit{k}mer in a set of 20 million reads of length 150.
This dramatic increase in efficiency is achieved despite having to copy each chunk of raw data read from the FASTA file to the GPU memory before processing can begin.
Recall that in section \ref{methods:initial_testing:assessment}, we justified only benchmarking the time spent counting \textit{k}mers on the GPU without including the overhead of copying the \textit{k}mer chunks to the GPU memory.
Combined with the \textit{k}mer hashing component's GPU acceleration, which yields a dramatic increase in efficiency despite including this overhead, \textit{k}mer chunks that are hashed on the GPU will already reside in the GPU's memory for counting.
